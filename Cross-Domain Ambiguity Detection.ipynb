{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom gensim.models.word2vec import Word2Vec\nfrom gensim.models.callbacks import CallbackAny2Vec\nfrom os import path\nfrom pprint import pprint\nfrom scipy.linalg import norm, orthogonal_procrustes\nfrom scipy.spatial.distance import cosine\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport spacy\n\nclass EpochLogger(CallbackAny2Vec):\n    def __init__(self):\n        self.epoch = 0\n    def on_epoch_begin(self, model):\n        print(\"Epoch #{} start\".format(self.epoch))\n    def on_epoch_end(self, model):\n        print(\"Epoch #{} end\".format(self.epoch))\n        self.epoch += 1\n\nMODEL_PATH = \"../input/domain-word2vec\"\n\nmodels = dict()\n\nmodels['cs'] = Word2Vec.load(path.join(MODEL_PATH, \"cs.bin\"))\nmodels['med'] = Word2Vec.load(path.join(MODEL_PATH, \"medicine.bin\"))\nmodels['sport'] = Word2Vec.load(path.join(MODEL_PATH, \"sports.bin\"))\nmodels['ele'] = Word2Vec.load(path.join(MODEL_PATH, \"ee.bin\"))\nmodels['mec'] = Word2Vec.load(path.join(MODEL_PATH, \"me.bin\"))","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    \n    # Mean centering\n    words = []\n    matrix = []\n    for word in models[model].wv.vocab:\n        words.append(word)\n        matrix.append(models[model].wv[word])\n    mean = np.mean(matrix, axis=0)\n    models[model].wv.add(words, matrix - mean, replace=True)\n    \n    # Length normalization\n    models[model].init_sims(replace=True)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en')\ntags = dict()\n\ndef get_tag(word):\n    if word in tags:\n        return tags[word]\n    tag = list(nlp(word))[0].pos_\n    tags[word] = tag\n    return tag","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ambiguity_scores(domains, min_freq=800, min_ratio=0.3, th=0.001):\n\n    vocab = set()\n    for domain in domains:\n        vocab = vocab.union(models[domain].wv.vocab.keys())\n    Y = dict()\n    c = dict()\n    for word in vocab:\n        Y[word] = np.zeros((50,))\n        c[word] = 0\n    for domain in domains:\n        for word in models[domain].wv.vocab:\n            Y[word] += models[domain].wv[word]\n            c[word] += 1\n    for word in vocab:\n        Y[word] /= c[word]\n    vectors = dict()\n    for word in models[domains[0]].wv.vocab:\n        vectors[word + '_' + domains[0]] = models[domains[0]].wv[word] \n    matrix = dict()\n    iteration = 1\n    errors = []\n    while True:\n        for domain in domains:\n            X = []\n            y = []\n            for word in models[domain].wv.vocab:\n                X.append(models[domain].wv[word])\n                y.append(Y[word])\n            X, y = np.array(X), np.array(y)\n            \n            matrix[domain], _ = orthogonal_procrustes(X, y, check_finite=False)\n        \n        for word in vocab:\n            Y[word] = np.zeros((50,))\n        for domain in domains:\n            for word in models[domain].wv.vocab:\n                Y[word] += np.matmul(models[domain].wv[word], matrix[domain])\n        for word in vocab:\n            Y[word] /= c[word]\n        \n        e = 0\n        for domain in domains:\n            X = []\n            y = []\n            for word in models[domain].wv.vocab:\n                X.append(models[domain].wv[word])\n                y.append(Y[word])\n            e += norm(y - np.matmul(X, matrix[domain])) / ((len(y) * 50) ** 0.5)\n        e /= len(domains)\n        errors.append(e)\n        if iteration > 1:\n            if e_prev - e < th:\n                break\n        e_prev = e\n        iteration += 1\n    \n    for domain in domains:\n        for word in models[domain].wv.vocab:\n            vectors[word + '_' + domain] = np.matmul(models[domain].wv[word], matrix[domain])\n\n    word_scores = []    \n    for word in vocab:\n        if len(word) == 1 or word.isnumeric() or get_tag(word) not in ['NOUN', 'PROPN', 'VERB', 'ADJ']:\n            continue\n        v = []\n        d = []\n        counts = []\n        for domain in domains:\n            try:\n                counts.append(models[domain].wv.vocab[word].count)\n            except KeyError:\n                counts.append(0)\n        counts.sort()\n        if counts[-1] < min_freq or counts[-2] < min_ratio * counts[-1]:\n            continue\n        for domain in domains:\n            if word + '_' + domain in vectors:# and models[domain].wv.vocab[word].count >= min_ratio * max_freq:\n                d.append(domain)\n                v.append((domain, word, vectors[word + '_' + domain]))\n        l = len(d)\n        if l > 1:\n            cos = 0\n            weight_sum = 0\n            for i in range(l - 1):\n                for j in range(i + 1, l):\n                    weight = models[v[i][0]].wv.vocab[v[i][1]].count + models[v[j][0]].wv.vocab[v[j][1]].count\n                    cos += cosine(v[i][2], v[j][2]) * weight\n                    weight_sum += weight\n            word_scores.append([word, cos / weight_sum, d])\n    \n    return sorted(word_scores, key=lambda x : x[1], reverse=True), matrix, errors","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ambiguity_scores_ferrari(domains, min_freq=800, min_ratio=0.3, w2v_topn=100):\n    output = list()\n    vocab = set()\n    for domain in domains:\n        vocab = vocab.union(models[domain].wv.vocab.keys())\n        \n    for word in vocab:\n        if len(word) == 1 or word.isnumeric() or get_tag(word) not in ['NOUN', 'PROPN', 'VERB', 'ADJ']:\n            continue\n        counts = []\n        for domain in domains:\n            try:\n                counts.append(models[domain].wv.vocab[word].count)\n            except KeyError:\n                counts.append(0)\n        counts.sort()\n        if counts[-1] < min_freq or counts[-2] < min_ratio * counts[-1]:\n            continue\n        sorted_tops = list()\n        sorted_words = list()\n        tops = list()\n        for domain in domains:\n            try:\n                sorted_tops.append(models[domain].wv.most_similar(word, topn=w2v_topn))\n            except:\n                continue\n            sorted_words.append([word for word, score in sorted_tops[-1]])\n            tops.append(dict(sorted_tops[-1]))\n        \n        shared = set()\n        for top_word in tops:\n            shared.update(top_word.keys())\n\n        mse = 0\n        for shared_word in shared:\n            min_rank = w2v_topn + 1\n\n            for sorted_word in sorted_words:\n                try:\n                    min_rank = min(min_rank, sorted_word.index(shared_word) + 1)\n                except:\n                    pass\n            scores = list()\n            for top in tops:\n                scores.append(top.get(shared_word, 0))\n\n            mse += np.var(scores) / min_rank\n        counts = list()\n        for domain in domains:\n            try:\n                counts.append(models[domain].wv.vocab[word].count)\n            except KeyError:\n                counts.append(0)\n        output.append((word, len(shared), mse, counts))\n    return sorted(output, key=lambda x: -x[2])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrices = []\nerrors = []\nscenarios = {'CS_EEN': ['cs', 'ele'],\n             'CS_MEN': ['cs', 'mec'],\n             'CS_MED': ['cs', 'med'],\n             'CS_SPO': ['cs', 'sport'],\n             'medical_device': ['cs', 'ele', 'med'],\n             'medical_robot': ['cs', 'ele', 'mec', 'med'],\n             'sport_rehab_machine': ['cs', 'ele', 'mec', 'med', 'sport']}\nambiguous = []\nfor scenario_name in scenarios:   \n    ambiguous, domain_matrix, e = get_ambiguity_scores(scenarios[scenario_name], 1000, 0.5, 0.001)\n    ambiguous_ferrari = get_ambiguity_scores_ferrari(scenarios[scenario_name], 1000, 0.5)\n    matrices.append(domain_matrix)\n    errors.append(e)\n    print(scenario_name, len(ambiguous), '\\n')\n    pprint([(term, score, domains) for (term, score, domains) in ambiguous[:10]], width=200)\n    pprint([(term, score, domains) for (term, score, domains) in ambiguous[len(ambiguous)-10:]], width=200)\n    \n    l = []\n    for i in range(len(ambiguous)):\n        for j in range(len(ambiguous_ferrari)):\n            if ambiguous_ferrari[j][0]==ambiguous[i][0]:\n                l.append([ambiguous[i][0], i, j, abs(i-j)])\n    l.sort(key=lambda x:x[3])\n    print()\n    pprint([(w,i,j,d) for (w,i,j,d) in l[len(l)-10:]], width=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='dark')\nplt.figure(figsize=(10, 10))\nax = sns.lineplot(x=range(1,len(errors[0]) + 1), y=errors[0], label=list(scenarios.keys())[0])\nfor i in range(1, 7):\n    sns.lineplot(x=range(1,len(errors[i]) + 1), y=errors[i], label=list(scenarios.keys())[i], ax=ax)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}